{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 14 14:37:24 2017\n",
    "@author: liulo\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pylab\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import smote\n",
    "\n",
    "\n",
    "def split_data(data):\n",
    "    data_len = data['y'].count()\n",
    "    split1 = int(data_len*0.6)\n",
    "    split2 = int(data_len*0.8)\n",
    "    train_data = data[:split1]\n",
    "    cv_data = data[split1:split2]\n",
    "    test_data = data[split2:]\n",
    "    \n",
    "    return train_data, cv_data, test_data\n",
    "\n",
    "\n",
    "def resample_train_data(train_data, n, frac):\n",
    "    numeric_attrs = ['age', 'duration', 'campaign', 'pdays', 'previous',\n",
    "                 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                 'euribor3m', 'nr.employed',]\n",
    "    #numeric_attrs = train_data.drop('y',axis=1).columns\n",
    "    pos_train_data_original = train_data[train_data['y'] == 1]\n",
    "    pos_train_data = train_data[train_data['y'] == 1]\n",
    "    new_count = n * pos_train_data['y'].count()\n",
    "    neg_train_data = train_data[train_data['y'] == 0].sample(frac=frac)\n",
    "    train_list = []\n",
    "    if n != 0:\n",
    "        pos_train_X = pos_train_data[numeric_attrs]\n",
    "        pos_train_X2 = pd.concat([pos_train_data.drop(numeric_attrs, axis=1)] * n)\n",
    "        pos_train_X2.index = range(new_count)\n",
    "        \n",
    "        s = smote.Smote(pos_train_X.values, N=n, k=3)\n",
    "        pos_train_X = s.over_sampling()\n",
    "        pos_train_X = pd.DataFrame(pos_train_X, columns=numeric_attrs, \n",
    "                                   index=range(new_count))\n",
    "        pos_train_data = pd.concat([pos_train_X, pos_train_X2], axis=1)\n",
    "        pos_train_data = pd.DataFrame(pos_train_data, columns=pos_train_data_original.columns)\n",
    "        train_list = [pos_train_data, neg_train_data, pos_train_data_original]\n",
    "    else:\n",
    "        train_list = [neg_train_data, pos_train_data_original]\n",
    "    print(\"Size of positive train data: {} * {}\".format(pos_train_data_original['y'].count(), n+1))\n",
    "    print(\"Size of negative train data: {} * {}\".format(neg_train_data['y'].count(), frac))\n",
    "    train_data = pd.concat(train_list, axis=0)\n",
    "    return shuffle(train_data)\n",
    "    \n",
    "    \n",
    "def evaluate(test_predictY, test_y):\n",
    "    test_len = test_y.shape[0]\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    for i in range(test_len):\n",
    "        if test_predictY[i] == 1:\n",
    "            if test_y[i] == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "        else:\n",
    "            if test_y[i] == 0:\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                false_neg += 1\n",
    "    \n",
    "    accuracy = 1.0 * (true_pos+true_neg) / test_len\n",
    "    precision  = 1.0 * true_pos / (true_pos + false_pos)\n",
    "    recall = 1.0 * true_pos / (true_pos + false_neg)\n",
    "    f1Score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    print(\"Precision: {}\".format(precision ))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F1 Score: {}\".format(f1Score))\n",
    "\n",
    "\n",
    "def plot_pr(auc_score, precision, recall, label=None):  \n",
    "    pylab.figure(num=None, figsize=(6, 5))  \n",
    "    pylab.xlim([0.0, 1.0])  \n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')  \n",
    "    pylab.ylabel('Precision')  \n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))  \n",
    "    pylab.fill_between(recall, precision, alpha=0.2)  \n",
    "    pylab.grid(True, linestyle='-', color='0.75')  \n",
    "    pylab.plot(recall, precision, lw=1)      \n",
    "    pylab.show()\n",
    "    \n",
    "\n",
    "\n",
    "def plot_roc(auc_score, fpr, tpr, label=None):  \n",
    "    pylab.figure(num=None, figsize=(6, 5))  \n",
    "    pylab.xlim([0.0, 1.0])  \n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('False positive rate')  \n",
    "    pylab.ylabel('True positive rate')  \n",
    "    pylab.title('ROC (AUC=%0.2f) / %s' % (auc_score, label))  \n",
    "    pylab.fill_between(fpr, tpr, alpha=0.2)  \n",
    "    pylab.grid(True, linestyle='-', color='0.75')  \n",
    "    pylab.plot(fpr, tpr, lw=1)      \n",
    "    pylab.show()\n",
    "\n",
    "\n",
    "def train_evaluate(train_data, test_data, classifier, n=1, frac=1.0, threshold = 0.5):  \n",
    "    train_data = resample_train_data(train_data, n, frac)\n",
    "    train_X = train_data.drop('y',axis=1)\n",
    "    train_y = train_data['y']\n",
    "    test_X = test_data.drop('y', axis=1)\n",
    "    test_y = test_data['y']\n",
    "    \n",
    "    classifier = classifier.fit(train_X, train_y)\n",
    "    prodict_prob_y = classifier.predict_proba(test_X)[:,1]\n",
    "    report = classification_report(test_y, prodict_prob_y > threshold,\n",
    "                                   target_names = ['no', 'yes'])\n",
    "    prodict_y = (prodict_prob_y > threshold).astype(int)\n",
    "    accuracy = np.mean(test_y.values == prodict_y)\n",
    "    print(\"Accuracy: {}\".format(accuracy))    \n",
    "    print(report)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y, prodict_prob_y)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(test_y, prodict_prob_y)  \n",
    "    test_auc = metrics.auc(fpr, tpr)\n",
    "    plot_pr(test_auc, precision, recall, \"yes\")\n",
    "    \n",
    "    return prodict_y\n",
    "  #  print(\"AUC: {}\".format(test_auc))\n",
    "  #  plot_roc(test_auc, fpr, tpr, \"yes\")\n",
    "\n",
    "\n",
    "def select_model(train_data, cv_data):\n",
    "    for i in range(1):\n",
    "      #  print(\"n_estimators: {}\".format(i))\n",
    "      #  print(\"threshold: {}\".format(i/50.0))\n",
    "      #  print(\"n: {}\".format(i))\n",
    "        forest = RandomForestClassifier(n_estimators=400, oob_score=True)\n",
    "        #lr = LogisticRegression(max_iter=100, C=1, random_state=0)\n",
    "        train_evaluate(train_data, cv_data, forest, n=7, frac=1.0, threshold=0.4)\n",
    "    \n",
    "\n",
    "def find_key_attrs(forest):\n",
    "    feature_importance = forest.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    fi_threshold = 5\n",
    "    important_idx = np.where(feature_importance > fi_threshold)[0]\n",
    "    important_features = features_list[important_idx]\n",
    "    print \"\\n\", important_features.shape[0], \"Important features(>\", \\\n",
    "          fi_threshold, \"% of max importance)...\\n\"#, \\\n",
    "            #important_features\n",
    "    sorted_idx = np.argsort(feature_importance[important_idx])[::-1]\n",
    "    #get the figure about important features\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.barh(pos, feature_importance[important_idx][sorted_idx[::-1]], \\\n",
    "            color='r',align='center')\n",
    "    plt.yticks(pos, important_features[sorted_idx[::-1]])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "processed_data = '../processed_data/bank-additional-full.csv'\n",
    "data = pd.read_csv(processed_data)\n",
    "train_data, cv_data, test_data = split_data(data)\n",
    "\n",
    "features_list = train_data.drop('y',axis=1).columns\n",
    "select_model(train_data, cv_data)\n",
    "start_time = datetime.now()\n",
    "import matplotlib.pyplot as plt\n",
    "print('Training...')\n",
    "forest = RandomForestClassifier(n_estimators=400, oob_score=True)\n",
    "prodict_y = train_evaluate(train_data, test_data, forest, n=7, frac=1, threshold=0.40)\n",
    "# find_key_attrs(forest)\n",
    "\n",
    "end_time = datetime.now()\n",
    "delta_seconds = (end_time - start_time).seconds\n",
    "\n",
    "print(\"Cost time: {}s\".format(delta_seconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
