{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-db41f862-c5b2-4593-a4e5-e8a3982c3165",
    "tags": []
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"figure.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.titlepad\"] = 10.0\n",
    "plt.rcParams[\"axes.titlelocation\"] = \"left\"\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "import seaborn as sns\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(filename):\n",
    "    bank_mkt = pd.read_csv(filename,\n",
    "                           na_values=[\"unknown\", \"nonexistent\"],\n",
    "                           true_values=[\"yes\", \"success\"],\n",
    "                           false_values=[\"no\", \"failure\"])\n",
    "    # Treat pdays = 999 as missing values\n",
    "    bank_mkt[\"pdays\"] = bank_mkt[\"pdays\"].replace(999, pd.NA)\n",
    "    # Convert types, \"Int64\" is nullable integer data type in pandas\n",
    "    bank_mkt = bank_mkt.astype(dtype={\"age\": \"Int64\",\n",
    "                                      \"job\": \"category\",\n",
    "                                      \"marital\": \"category\",\n",
    "                                      \"education\": \"category\",\n",
    "                                      \"default\": \"boolean\",\n",
    "                                      \"housing\": \"boolean\",\n",
    "                                      \"loan\": \"boolean\",\n",
    "                                      \"contact\": \"category\",\n",
    "                                      \"month\": \"category\",\n",
    "                                      \"day_of_week\": \"category\",\n",
    "                                      \"duration\": \"Int64\",\n",
    "                                      \"campaign\": \"Int64\",\n",
    "                                      \"pdays\": \"Int64\",\n",
    "                                      \"previous\": \"Int64\",\n",
    "                                      \"poutcome\": \"boolean\",\n",
    "                                      \"y\": \"boolean\"})\n",
    "    # Drop duplicates\n",
    "    bank_mkt = bank_mkt.drop_duplicates().reset_index(drop=True)\n",
    "    # reorder categorical data\n",
    "    bank_mkt[\"education\"] = bank_mkt[\"education\"].cat.reorder_categories([\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \"high.school\", \"professional.course\", \"university.degree\"], ordered=True)\n",
    "    bank_mkt[\"month\"] = bank_mkt[\"month\"].cat.reorder_categories([\"mar\", \"apr\", \"jun\", \"jul\", \"may\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"], ordered=True)\n",
    "    bank_mkt[\"day_of_week\"] = bank_mkt[\"day_of_week\"].cat.reorder_categories([\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"], ordered=True)\n",
    "    return bank_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_mkt = import_dataset(\"../data/BankMarketing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_split.split(bank_mkt.drop(\"y\", axis=1), bank_mkt[\"y\"]):\n",
    "    bank_train_set = bank_mkt.loc[train_index].reset_index(drop=True)\n",
    "    bank_test_set = bank_mkt.loc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that should be encoded as their target mean value\n",
    "combine_features = [\"job\", \"education\"]\n",
    "\n",
    "combine_name = \".\".join(combine_features)\n",
    "\n",
    "# Features with missing values that should be imputed by IterativeImputer\n",
    "ite_features = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Features that should be mean encoded\n",
    "# target_features = [\"age\", \"job\", \"marital\", \"education\", \"month\", \"day_of_week\", \"pdays\", combine_name]\n",
    "target_features = [\"age\", \"job\", \"marital\", \"education\", \"month\", \"day_of_week\", \"pdays\", combine_name]\n",
    "\n",
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    # X[\"pdays\"] = pd.qcut(X[\"pdays\"], [0, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 1], duplicates=\"drop\")\n",
    "    X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 20, 25, 30, 1000], labels=[1, 2, 3, 4, 5, 6, 7], include_lowest=True).astype(\"Int64\")\n",
    "    # Cut age into age groups\n",
    "    X[\"age\"] = pd.cut(X[\"age\"], [0, 18, 24, 30, 40, 50,60, 70, 100], labels=[18, 24, 30, 40, 50, 60, 70, 100], include_lowest=True).astype(\"Int64\")\n",
    "    # Feature interactions\n",
    "    # combine_features = [\"education\", \"job\"]\n",
    "    # combine_name = \"_\".join(combine_features)\n",
    "    X[combine_name] = X[combine_features].astype(\"str\").apply(lambda x: \".\".join(x), axis=1)\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"may\": 5,\n",
    "                 \"jun\": 6,\n",
    "                 \"jul\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    X[\"month\"] = X[\"month\"].replace(month_map).astype(\"Int64\")\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    cat_features = [\"job\", \"education\", \"marital\", \"day_of_week\", \"contact\"]\n",
    "    bool_features = [\"default\", \"housing\", \"loan\", \"poutcome\"]\n",
    "    X[cat_features] = X[cat_features].apply(lambda x: x.cat.codes).astype(\"Int64\")\n",
    "    X[bool_features] = X[bool_features].astype(\"Int64\")\n",
    "    X[target_features] = X[target_features].astype(\"str\")\n",
    "    # Fill missing values as -1\n",
    "    X = X.fillna(-1)\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "# Features with missing values that should be imputed with most freq value\n",
    "freq_features = [\"job\", \"education\", \"marital\", \"default\", \"housing\", \"loan\"]\n",
    "# freq_features = [1, 2, 3, 4, 5, 6]\n",
    "# freq_imputer will impute missing values in columns specified by freq_features\n",
    "freq_imputer = ColumnTransformer([\n",
    "    (\"freq_imputer\",\n",
    "     SimpleImputer(missing_values=-1, strategy=\"most_frequent\"),\n",
    "     freq_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "#ite_features = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "ite_imputer = Pipeline([\n",
    "    (\"ite_imputer\", IterativeImputer(max_iter=1000, missing_values=-1, initial_strategy=\"most_frequent\", random_state=42)),\n",
    "    (\"ite_round\", FunctionTransformer(np.round))\n",
    "])\n",
    "\n",
    "ite_transformer = ColumnTransformer([(\"ite_imputer\", ite_imputer, ite_features)], remainder=\"passthrough\")\n",
    "\n",
    "target_encoder = TargetEncoder(cols=target_features, return_df=True)\n",
    "\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", tree_encoder),\n",
    "    (\"target_encoder\", target_encoder),\n",
    "    (\"ite_transformer\", ite_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/analytics/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_duration = bank_train_set[\"duration\"].astype(\"int\").to_numpy()\n",
    "X_train = tree_preprocessor.fit_transform(bank_train_set.drop([\"duration\", \"y\"], axis=1), X_duration)\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_test = tree_preprocessor.transform(bank_test_set.drop([\"duration\", \"y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_split.split(X_train, y_train):\n",
    "    X_ttrain = X_train[train_index]\n",
    "    y_ttrain = y_train[train_index]\n",
    "    X_validate = X_train[test_index]\n",
    "    y_validate = y_train[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-026bc890-d956-41e0-827d-1d80d6e6cdac",
    "tags": []
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.864602</td>\n",
       "      <td>0.866746</td>\n",
       "      <td>0.870142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.653419</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>0.658405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.753454</td>\n",
       "      <td>0.764274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.835416</td>\n",
       "      <td>0.813876</td>\n",
       "      <td>0.809554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.653419</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>0.658405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.379945</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.391667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.480495</td>\n",
       "      <td>0.475952</td>\n",
       "      <td>0.491158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.526257</td>\n",
       "      <td>0.475124</td>\n",
       "      <td>0.480411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validation      Test\n",
       "TNR   0.864602    0.866746  0.870142\n",
       "TPR   0.653419    0.640162  0.658405\n",
       "bACC  0.759011    0.753454  0.764274\n",
       "ROC   0.835416    0.813876  0.809554\n",
       "REC   0.653419    0.640162  0.658405\n",
       "PRE   0.379945    0.378788  0.391667\n",
       "F1    0.480495    0.475952  0.491158\n",
       "AP    0.526257    0.475124  0.480411"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(max_depth=3, scale_pos_weight=8)\n",
    "xgb_fit = xgb_clf.fit(X_ttrain, y_ttrain)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validation\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = xgb_clf.predict(X)\n",
    "    y_score = xgb_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.864602</td>\n",
       "      <td>0.866746</td>\n",
       "      <td>0.870142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.653419</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>0.658405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.753454</td>\n",
       "      <td>0.764274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.835416</td>\n",
       "      <td>0.813876</td>\n",
       "      <td>0.809554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.653419</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>0.658405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.379945</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.391667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.480495</td>\n",
       "      <td>0.475952</td>\n",
       "      <td>0.491158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.526257</td>\n",
       "      <td>0.475124</td>\n",
       "      <td>0.480411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validation      Test\n",
       "TNR   0.864602    0.866746  0.870142\n",
       "TPR   0.653419    0.640162  0.658405\n",
       "bACC  0.759011    0.753454  0.764274\n",
       "ROC   0.835416    0.813876  0.809554\n",
       "REC   0.653419    0.640162  0.658405\n",
       "PRE   0.379945    0.378788  0.391667\n",
       "F1    0.480495    0.475952  0.491158\n",
       "AP    0.526257    0.475124  0.480411"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(eval_metric=\"AUC\", verbose=False)\n",
    "cat_fit = cat_clf.fit(X_ttrain, y_ttrain)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validation\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = xgb_clf.predict(X)\n",
    "    y_score = xgb_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.46760831263553626, for {'max_depth': 3, 'scale_pos_weight': 8}.\n",
      "mean test score: 0.4273262687987603, mean train score: 0.4273262687987603, for {'max_depth': 6, 'scale_pos_weight': 8}.\n",
      "mean test score: 0.4460181827046707, mean train score: 0.4460181827046707, for {'max_depth': 5, 'scale_pos_weight': 8}.\n",
      "mean test score: 0.46325870536142977, mean train score: 0.46325870536142977, for {'max_depth': 4, 'scale_pos_weight': 8}.\n",
      "mean test score: 0.46760831263553626, mean train score: 0.46760831263553626, for {'max_depth': 3, 'scale_pos_weight': 8}.\n",
      "mean test score: 0.4645482149350781, mean train score: 0.4645482149350781, for {'max_depth': 2, 'scale_pos_weight': 8}.\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "param_grid = [\n",
    "    {\"max_depth\": [6, 5, 4, 3, 2],\n",
    "     \"scale_pos_weight\": [8]}\n",
    "    ]\n",
    "grid_search = GridSearchCV(xgb_clf,\n",
    "                           param_grid,\n",
    "                           scoring=\"average_precision\",\n",
    "                           # scoring=\"roc_auc\",\n",
    "                           return_train_score=True,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_fit = grid_search.fit(X_train, y_train)\n",
    "grid_results = grid_search.cv_results_\n",
    "grid_best_params = grid_search.best_params_\n",
    "grid_best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"best mean test score: {grid_best_score}, for {grid_best_params}.\")\n",
    "\n",
    "for test_score, train_score, params in zip(grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"params\"]):\n",
    "    print(f\"mean test score: {test_score}, mean train score: {train_score}, for {params}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "0cc1ea8a-807a-4fa9-9229-d2534fec09f5",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
