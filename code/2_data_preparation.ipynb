{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-1b1ea3a8-0c37-42cd-a71c-4fa63218b051",
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-5cf04d27-6f80-4c90-94b3-e82e08b438f4",
    "execution_millis": 1,
    "execution_start": 1603100785978,
    "output_cleared": false,
    "source_hash": "b7dcc9c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00007-ee50a782-f279-435b-b785-c002d0440d0a",
    "execution_millis": 2,
    "execution_start": 1603102496110,
    "output_cleared": false,
    "source_hash": "abe646a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_dataset(filename):\n",
    "    bank_mkt = pd.read_csv(filename,\n",
    "                           na_values=[\"unknown\", \"nonexistent\"],\n",
    "                           true_values=[\"yes\", \"success\"],\n",
    "                           false_values=[\"no\", \"failure\"])\n",
    "    # Treat pdays = 999 as missing values\n",
    "    bank_mkt[\"pdays\"] = bank_mkt[\"pdays\"].replace(999, pd.NA)\n",
    "    # Convert types, \"Int64\" is nullable integer data type in pandas\n",
    "    bank_mkt = bank_mkt.astype(dtype={\"age\": \"Int64\",\n",
    "                                      \"job\": \"category\",\n",
    "                                      \"marital\": \"category\",\n",
    "                                      \"education\": \"category\",\n",
    "                                      \"default\": \"boolean\",\n",
    "                                      \"housing\": \"boolean\",\n",
    "                                      \"loan\": \"boolean\",\n",
    "                                      \"contact\": \"category\",\n",
    "                                      \"month\": \"category\",\n",
    "                                      \"day_of_week\": \"category\",\n",
    "                                      \"duration\": \"Int64\",\n",
    "                                      \"campaign\": \"Int64\",\n",
    "                                      \"pdays\": \"Int64\",\n",
    "                                      \"previous\": \"Int64\",\n",
    "                                      \"poutcome\": \"boolean\",\n",
    "                                      \"y\": \"boolean\"})\n",
    "    # reorder categorical data\n",
    "    bank_mkt[\"education\"] = bank_mkt[\"education\"].cat.reorder_categories([\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \"high.school\", \"professional.course\", \"university.degree\"], ordered=True)\n",
    "    bank_mkt[\"month\"] = bank_mkt[\"month\"].cat.reorder_categories([\"mar\", \"apr\", \"jun\", \"jul\", \"may\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"], ordered=True)\n",
    "    bank_mkt[\"day_of_week\"] = bank_mkt[\"day_of_week\"].cat.reorder_categories([\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"], ordered=True)\n",
    "    return bank_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00009-8df480dc-278d-4405-94c0-c3d127149c5c",
    "execution_millis": 702,
    "execution_start": 1603102496849,
    "output_cleared": false,
    "source_hash": "d85a72d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bank_mkt = import_dataset(\"../data/BankMarketing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-7890358b-f90c-4768-acb3-8c9ec04ea388",
    "tags": []
   },
   "source": [
    "## Partition\n",
    "\n",
    "We need to split the dataset into trainning set and test set, then we train models on the trainning set and only use test set for final validation purposes. However, simply sampling the dataset may lead to unrepresenatative partition given that our dataset is imbalanced and clients have different features. Luckily, `scikit-learn` provides a useful function to select representative data as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00016-ceca7260-e01b-49fc-8cb5-0ea816504667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00016-ceca7260-e01b-49fc-8cb5-0ea816504667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_split.split(bank_mkt.drop(\"y\", axis=1), bank_mkt[\"y\"]):\n",
    "    bank_train_set = bank_mkt.loc[train_index].reset_index(drop=True)\n",
    "    bank_test_set = bank_mkt.loc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-73d59ba8-50e9-4557-8ca0-800cb3b3ef65"
   },
   "source": [
    "## Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several strategies to handle the missing values. For categorical data, we can either treat missing value as a different category or impute them as the most frequent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['blue-collar', 'married', 'basic.9y'],\n",
       "       ['entrepreneur', 'married', 'university.degree'],\n",
       "       ['retired', 'married', 'basic.4y'],\n",
       "       ...,\n",
       "       ['admin.', 'married', 'basic.9y'],\n",
       "       ['admin.', 'married', 'university.degree'],\n",
       "       ['admin.', 'married', 'university.degree']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [\"job\", \"marital\", \"education\"]\n",
    "X = bank_train_set.drop([\"duration\", \"y\"], axis=1)\n",
    "X_cat = X[cat_features]\n",
    "freq_imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "freq_imp.fit_transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['blue-collar', 'married', 'basic.9y'],\n",
       "       ['entrepreneur', 'married', 'university.degree'],\n",
       "       ['retired', 'married', 'basic.4y'],\n",
       "       ...,\n",
       "       ['admin.', 'married', 'basic.9y'],\n",
       "       ['admin.', 'married', 'university.degree'],\n",
       "       ['admin.', 'married', 'university.degree']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = X[cat_features]\n",
    "fill_imp = SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")\n",
    "fill_imp.fit_transform(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in boolean data is more tricky and requires `pandas` to transform the data first because `SimpleImputer` can not fill nullable boolean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       ...,\n",
       "       [False, False, True],\n",
       "       [False, False, False],\n",
       "       [False, False, True]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_features=[\"default\", \"housing\", \"loan\"]\n",
    "X_bool = X[bool_features].astype(\"category\")\n",
    "freq_imp.fit_transform(X_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['unknown', False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       ...,\n",
       "       [False, False, True],\n",
       "       [False, False, False],\n",
       "       [False, False, True]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bool = X[bool_features].astype(\"category\")\n",
    "fill_imp.fit_transform(X_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, some clients do not have `pdays` but have `poutcome`, which implies that they may have been contacted before but the `pdays` is more than 30 days therefore not inluded. `pdays` can also be cut into different categories which is known as the discretization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1        pdays>30\n",
       "2             NaN\n",
       "3             NaN\n",
       "4             NaN\n",
       "           ...   \n",
       "32945         NaN\n",
       "32946    pdays>30\n",
       "32947         NaN\n",
       "32948         NaN\n",
       "32949         NaN\n",
       "Name: pdays, Length: 32950, dtype: category\n",
       "Categories (5, object): ['pdays<=5' < 'pdays<=10' < 'pdays<=15' < 'pdays<=30' < 'pdays>30']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pdays = X[\"pdays\"]\n",
    "X_pdays[X[\"pdays\"].isna() & X[\"poutcome\"].notna()] = 999\n",
    "pd.cut(X_pdays, [0, 5, 10, 15, 30, 1000], labels=[\"pdays<=5\", \"pdays<=10\", \"pdays<=15\", \"pdays<=30\", \"pdays>30\"], include_lowest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-4c9fc12b-bbe4-422a-b0a4-3b0c970cd34f",
    "tags": []
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00020-fe2e88a4-0cde-44ca-b5e1-11349f09f0ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`education`, `month` and `day_of_week` are ordinal data. We can say `basic.6y` is more \"advanced\" than `basic.4y` for example. Therefore, we should encode `education` into ordinal values or transform them into years of `education`. The same logic also goes for `month` and `day_of_week`. Even though `sklearn` has its own `OrdinalEncoder`, it is using alphabatical order therefore we use pandas instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32945</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32946</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32948</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32949</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32950 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education  month  day_of_week\n",
       "0              3      8            2\n",
       "1              6      8            2\n",
       "2              1      3            0\n",
       "3              6      4            0\n",
       "4              6      2            1\n",
       "...          ...    ...          ...\n",
       "32945          4      3            1\n",
       "32946          5      8            4\n",
       "32947          3      3            0\n",
       "32948          6      4            4\n",
       "32949          6      2            1\n",
       "\n",
       "[32950 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_features = [\"education\", \"month\", \"day_of_week\"]\n",
    "X_ord = X[ord_features]\n",
    "X_ord.apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need `OneHotEncoder` to transform categorical data into multiple binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed',\n",
       "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
       "       'marital_married', 'marital_single', 'default_True',\n",
       "       'housing_True', 'loan_True'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_features = [\"job\", \"marital\", \"default\", \"housing\", \"loan\"]\n",
    "one_hot_encoder = OneHotEncoder(drop=\"first\")\n",
    "X_one_hot = X[one_hot_features].astype(\"category\")\n",
    "X_one_hot = freq_imp.fit_transform(X_one_hot)\n",
    "one_hot_encoder.fit_transform(X_one_hot)\n",
    "one_hot_encoder.get_feature_names(one_hot_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done in `pandas`. The advantage of doing one hot encoding in `pandas` is that `pd.get_dummies()` can keep missing values as a row of `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-e7911c73-2733-4978-986f-35efb1bda1df",
    "tags": []
   },
   "source": [
    "## Transformation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then wrap all our transformations above into pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdays_transformation(X):\n",
    "    \"\"\"Feature Engineering `pdays`.\"\"\"\n",
    "    X = X.copy()\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[\"<=5\", \"<=10\", \"<=15\", \"<=30\", \">30\"], include_lowest=True)\n",
    "    return X\n",
    "\n",
    "def ordinal_transformation(X, education=None):\n",
    "    \"\"\"Encode ordinal labels.\n",
    "\n",
    "    education: if education is \"year\", education column will be encoded into years of eductaion.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    ordinal_features = [\"education\", \"month\", \"day_of_week\"]\n",
    "    X[ordinal_features] = X[ordinal_features].apply(lambda x: x.cat.codes)\n",
    "    if education==\"year\":\n",
    "        education_map = { 0: 0, # illiterate\n",
    "                          1: 4, # basic.4y\n",
    "                          2: 6, # basic.6y\n",
    "                          3: 9, # basic.9y\n",
    "                          4: 12, # high.school\n",
    "                          5: 15, # professional course\n",
    "                          6: 16} # university\n",
    "        X[\"education\"] = X[\"education\"].replace(education_map)\n",
    "    return X\n",
    "\n",
    "def bool_transformation(X):\n",
    "    \"\"\"Transform boolean data into categorical data.\"\"\"\n",
    "    X = X.copy()\n",
    "    bool_features = [\"default\", \"housing\", \"loan\", \"poutcome\"]\n",
    "    X[bool_features] = X[bool_features].astype(\"category\")\n",
    "    X[bool_features] = X[bool_features].replace({True: \"true\", False: \"false\"})\n",
    "    return X\n",
    "\n",
    "cut_transformer = FunctionTransformer(pdays_transformation)\n",
    "\n",
    "ordinal_transformer = FunctionTransformer(ordinal_transformation)\n",
    "\n",
    "bool_transformer = FunctionTransformer(bool_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_features = [\"job\", \"marital\", \"education\"]\n",
    "\n",
    "fill_features = [\"housing\", \"loan\", \"default\", \"pdays\", \"poutcome\"]\n",
    "\n",
    "one_hot_features = [\"contact\"]\n",
    "\n",
    "freq_transformer = Pipeline([\n",
    "    (\"freq_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"error\"))\n",
    "])\n",
    "\n",
    "fill_transformer = Pipeline([\n",
    "    (\"freq_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"error\"))\n",
    "])\n",
    "\n",
    "cat_transformer = ColumnTransformer([\n",
    "    (\"freq_imputer\", freq_transformer, freq_features),\n",
    "    (\"fill_imputer\", fill_transformer, fill_features),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"error\"), one_hot_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    (\"bool_transformer\", bool_transformer),\n",
    "    (\"cut_transformer\", cut_transformer),\n",
    "    (\"ordinal_transformer\", ordinal_transformer),\n",
    "    (\"cat_transformer\", cat_transformer),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(bank_train_set.drop([\"duration\", \"y\"], axis=1))\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-05cc8cbb-c4b6-45f4-83fc-32865dc9b388",
    "tags": []
   },
   "source": [
    "## Baseline Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00024-191c0674-bc01-4c62-9628-65183c0af970",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.086483</td>\n",
       "      <td>0.604940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.011415</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>10.609435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.311337</td>\n",
       "      <td>0.419526</td>\n",
       "      <td>0.335483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.199409</td>\n",
       "      <td>0.312006</td>\n",
       "      <td>0.507897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.771852</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.250540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.750778</td>\n",
       "      <td>0.781366</td>\n",
       "      <td>0.706039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Naive Bayes  Logistic Regression        KNN\n",
       "fit_time           0.013109             0.086483   0.604940\n",
       "score_time         0.011415             0.007786  10.609435\n",
       "test_f1            0.311337             0.419526   0.335483\n",
       "test_precision     0.199409             0.312006   0.507897\n",
       "test_recall        0.771852             0.640625   0.250540\n",
       "test_roc_auc       0.750778             0.781366   0.706039"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = [\"f1\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "# Initialize Model\n",
    "nb_model = GaussianNB()\n",
    "logit_model = LogisticRegression(class_weight=\"balanced\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# Train model and get CV results \n",
    "nb_cv = cross_validate(nb_model, X_train, y_train, scoring=scoring, cv = 5)\n",
    "logit_cv = cross_validate(logit_model, X_train, y_train, scoring=scoring, cv = 5)\n",
    "knn_cv = cross_validate(knn_model, X_train, y_train, scoring=scoring, cv = 5)\n",
    "# Calculate CV result mean\n",
    "nb_result = pd.DataFrame(nb_cv).mean().rename(\"Naive Bayes\")\n",
    "logit_result = pd.DataFrame(logit_cv).mean().rename(\"Logistic Regression\")\n",
    "knn_result = pd.DataFrame(knn_cv).mean().rename(\"KNN\")\n",
    "# Store and output result\n",
    "result = pd.concat([nb_result, logit_result, knn_result], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345568</td>\n",
       "      <td>0.440070</td>\n",
       "      <td>0.372325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224894</td>\n",
       "      <td>0.326552</td>\n",
       "      <td>0.550633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>0.674569</td>\n",
       "      <td>0.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.709712</td>\n",
       "      <td>0.748981</td>\n",
       "      <td>0.626056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dummy Classifier  Naive Bayes  Logistic Regression       KNN\n",
       "F1 Score                      0.0     0.345568             0.440070  0.372325\n",
       "Precision Score               0.0     0.224894             0.326552  0.550633\n",
       "Recall Score                  0.0     0.745690             0.674569  0.281250\n",
       "ROC AUC Score                 0.5     0.709712             0.748981  0.626056"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = preprocessor.transform(bank_test_set.drop([\"duration\", \"y\"], axis=1))\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "# Initialize and fit Model\n",
    "dummy_model = DummyClassifier(strategy=\"prior\").fit(X_train, y_train)\n",
    "nb_model = GaussianNB().fit(X_train, y_train)\n",
    "logit_model = LogisticRegression(class_weight=\"balanced\").fit(X_train, y_train)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "# Predict and calculate score\n",
    "dummy_predict = dummy_model.predict(X_test)\n",
    "dummy_f1 = f1_score(y_test, dummy_predict)\n",
    "dummy_precision = precision_score(y_test, dummy_predict)\n",
    "dummy_recall = recall_score(y_test, dummy_predict)\n",
    "dummy_roc_auc = roc_auc_score(y_test, dummy_predict)\n",
    "nb_predict = nb_model.predict(X_test)\n",
    "nb_f1 = f1_score(y_test, nb_predict)\n",
    "nb_precision = precision_score(y_test, nb_predict)\n",
    "nb_recall = recall_score(y_test, nb_predict)\n",
    "nb_roc_auc = roc_auc_score(y_test, nb_predict)\n",
    "logit_predict = logit_model.predict(X_test)\n",
    "logit_f1 = f1_score(y_test, logit_predict)\n",
    "logit_precision = precision_score(y_test, logit_predict)\n",
    "logit_recall = recall_score(y_test, logit_predict)\n",
    "logit_roc_auc = roc_auc_score(y_test, logit_predict)\n",
    "knn_predict = knn_model.predict(X_test)\n",
    "knn_f1 = f1_score(y_test, knn_predict)\n",
    "knn_precision = precision_score(y_test, knn_predict)\n",
    "knn_recall = recall_score(y_test, knn_predict)\n",
    "knn_roc_auc = roc_auc_score(y_test, knn_predict)\n",
    "# Store and output result\n",
    "result = pd.DataFrame(data={\"Dummy Classifier\": [dummy_f1, dummy_precision, dummy_recall, dummy_roc_auc],\n",
    "                            \"Naive Bayes\": [nb_f1, nb_precision, nb_recall, nb_roc_auc],\n",
    "                            \"Logistic Regression\": [logit_f1, logit_precision, logit_recall, logit_roc_auc],\n",
    "                            \"KNN\": [knn_f1, knn_precision, knn_recall, knn_roc_auc]},\n",
    "                       index=[\"F1 Score\", \"Precision Score\", \"Recall Score\", \"ROC AUC Score\"])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "888ca87c-c3cf-496e-9202-20738582021d",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
