{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-053f7d3f-467a-4af7-9ddb-b0fdf3cf6cf7",
    "tags": []
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"figure.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.titlepad\"] = 10.0\n",
    "plt.rcParams[\"axes.titlelocation\"] = \"left\"\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, balanced_accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(filename):\n",
    "    bank_mkt = pd.read_csv(filename,\n",
    "                           na_values=[\"unknown\", \"nonexistent\"],\n",
    "                           true_values=[\"yes\", \"success\"],\n",
    "                           false_values=[\"no\", \"failure\"])\n",
    "    # Treat pdays = 999 as missing values\n",
    "    bank_mkt[\"pdays\"] = bank_mkt[\"pdays\"].replace(999, pd.NA)\n",
    "    # Convert types, \"Int64\" is nullable integer data type in pandas\n",
    "    bank_mkt = bank_mkt.astype(dtype={\"age\": \"Int64\",\n",
    "                                      \"job\": \"category\",\n",
    "                                      \"marital\": \"category\",\n",
    "                                      \"education\": \"category\",\n",
    "                                      \"default\": \"boolean\",\n",
    "                                      \"housing\": \"boolean\",\n",
    "                                      \"loan\": \"boolean\",\n",
    "                                      \"contact\": \"category\",\n",
    "                                      \"month\": \"category\",\n",
    "                                      \"day_of_week\": \"category\",\n",
    "                                      \"duration\": \"Int64\",\n",
    "                                      \"campaign\": \"Int64\",\n",
    "                                      \"pdays\": \"Int64\",\n",
    "                                      \"previous\": \"Int64\",\n",
    "                                      \"poutcome\": \"boolean\",\n",
    "                                      \"y\": \"boolean\"})\n",
    "    # Drop duplicates\n",
    "    bank_mkt = bank_mkt.drop_duplicates().reset_index(drop=True)\n",
    "    # reorder categorical data\n",
    "    bank_mkt[\"education\"] = bank_mkt[\"education\"].cat.reorder_categories([\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \"high.school\", \"professional.course\", \"university.degree\"], ordered=True)\n",
    "    bank_mkt[\"month\"] = bank_mkt[\"month\"].cat.reorder_categories([\"mar\", \"apr\", \"jun\", \"jul\", \"may\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"], ordered=True)\n",
    "    bank_mkt[\"day_of_week\"] = bank_mkt[\"day_of_week\"].cat.reorder_categories([\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"], ordered=True)\n",
    "    return bank_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[1, 2, 3, 4, 5], include_lowest=True).astype(\"Int64\")\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"jun\": 5,\n",
    "                 \"jul\": 6,\n",
    "                 \"may\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    X[\"month\"] = X[\"month\"].replace(month_map).astype(\"int\")\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    cat_features = [\"job\", \"education\", \"marital\", \"contact\", \"day_of_week\"]\n",
    "    bool_features = [\"default\", \"housing\", \"loan\", \"poutcome\"]\n",
    "    X[cat_features] = X[cat_features].apply(lambda x: x.cat.codes).astype(\"Int64\")\n",
    "    X[bool_features] = X[bool_features].astype(\"Int64\")\n",
    "    # Fill missing values as -1\n",
    "    X = X.fillna(-1)\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "# Features with missing values that should be imputed with most freq value\n",
    "freq_features = [\"job\", \"education\", \"marital\", \"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# tree_imputer will impute missing values in columns specified by freq_features\n",
    "tree_imputer = ColumnTransformer([\n",
    "    (\"freq_imputer\",\n",
    "     SimpleImputer(missing_values=-1,strategy=\"most_frequent\"),\n",
    "     freq_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "# Wrap tree_encoder and tree_imputer in one pipeline\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"basic_encoder\", tree_encoder),\n",
    "    (\"tree_imputer\", tree_imputer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_mkt = import_dataset(\"../data/BankMarketing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_split.split(bank_mkt.drop(\"y\", axis=1), bank_mkt[\"y\"]):\n",
    "    bank_train_set = bank_mkt.loc[train_index].reset_index(drop=True)\n",
    "    bank_test_set = bank_mkt.loc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tree_preprocessor.fit_transform(bank_train_set.drop([\"duration\", \"y\"], axis=1))\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-026bc890-d956-41e0-827d-1d80d6e6cdac",
    "tags": []
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.4245309871344455, for {'criterion': 'gini', 'max_depth': 100000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.4183440906792913, mean train score: 0.4183440906792913, for {'criterion': 'gini', 'max_depth': 100000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.4245309871344455, mean train score: 0.4245309871344455, for {'criterion': 'gini', 'max_depth': 100000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 100000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 100000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4185390899908906, mean train score: 0.4185390899908906, for {'criterion': 'gini', 'max_depth': 50000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.4245309871344455, mean train score: 0.4245309871344455, for {'criterion': 'gini', 'max_depth': 50000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 50000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 50000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4185426755825272, mean train score: 0.4185426755825272, for {'criterion': 'gini', 'max_depth': 30000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42452913630535694, mean train score: 0.42452913630535694, for {'criterion': 'gini', 'max_depth': 30000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 30000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 30000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.41828084625315887, mean train score: 0.41828084625315887, for {'criterion': 'gini', 'max_depth': 20000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42452913630535694, mean train score: 0.42452913630535694, for {'criterion': 'gini', 'max_depth': 20000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 20000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 20000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.41842155878104315, mean train score: 0.41842155878104315, for {'criterion': 'gini', 'max_depth': 10000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.4245309871344455, mean train score: 0.4245309871344455, for {'criterion': 'gini', 'max_depth': 10000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 10000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 10000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.41867737084176904, mean train score: 0.41867737084176904, for {'criterion': 'gini', 'max_depth': 5000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.4245309871344455, mean train score: 0.4245309871344455, for {'criterion': 'gini', 'max_depth': 5000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.38292052914651087, mean train score: 0.38292052914651087, for {'criterion': 'gini', 'max_depth': 5000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'gini', 'max_depth': 5000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4192772300966672, mean train score: 0.4192772300966672, for {'criterion': 'entropy', 'max_depth': 100000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42450118452790947, mean train score: 0.42450118452790947, for {'criterion': 'entropy', 'max_depth': 100000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 100000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 100000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4190881003637433, mean train score: 0.4190881003637433, for {'criterion': 'entropy', 'max_depth': 50000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42450118452790947, mean train score: 0.42450118452790947, for {'criterion': 'entropy', 'max_depth': 50000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 50000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 50000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.41895189929595755, mean train score: 0.41895189929595755, for {'criterion': 'entropy', 'max_depth': 30000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42450118452790947, mean train score: 0.42450118452790947, for {'criterion': 'entropy', 'max_depth': 30000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 30000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 30000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4190106130188281, mean train score: 0.4190106130188281, for {'criterion': 'entropy', 'max_depth': 20000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.4242281195589178, mean train score: 0.4242281195589178, for {'criterion': 'entropy', 'max_depth': 20000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 20000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 20000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.4189990296884868, mean train score: 0.4189990296884868, for {'criterion': 'entropy', 'max_depth': 10000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42450118452790947, mean train score: 0.42450118452790947, for {'criterion': 'entropy', 'max_depth': 10000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 10000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 10000, 'max_leaf_nodes': 1}.\n",
      "mean test score: 0.419016322423419, mean train score: 0.419016322423419, for {'criterion': 'entropy', 'max_depth': 5000, 'max_leaf_nodes': 200}.\n",
      "mean test score: 0.42450118452790947, mean train score: 0.42450118452790947, for {'criterion': 'entropy', 'max_depth': 5000, 'max_leaf_nodes': 100}.\n",
      "mean test score: 0.3838147238783346, mean train score: 0.3838147238783346, for {'criterion': 'entropy', 'max_depth': 5000, 'max_leaf_nodes': 10}.\n",
      "mean test score: nan, mean train score: nan, for {'criterion': 'entropy', 'max_depth': 5000, 'max_leaf_nodes': 1}.\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "param_grid = [\n",
    "    {\"criterion\": [\"gini\", \"entropy\"],\n",
    "     \"max_depth\": [100000, 50000, 30000, 20000, 10000, 5000],\n",
    "     \"max_leaf_nodes\": [200, 100, 10, 1]}\n",
    "    ]\n",
    "grid_search = GridSearchCV(decision_tree,\n",
    "                           param_grid,\n",
    "                           scoring=\"average_precision\",\n",
    "                           return_train_score=True,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "grid_fit = grid_search.fit(X_train, y_train)\n",
    "grid_results = grid_search.cv_results_\n",
    "grid_best_params = grid_search.best_params_\n",
    "\n",
    "grid_fit = grid_search.fit(X_train, y_train)\n",
    "grid_results = grid_search.cv_results_\n",
    "grid_best_params = grid_search.best_params_\n",
    "grid_best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"best mean test score: {grid_best_score}, for {grid_best_params}.\")\n",
    "\n",
    "for test_score, train_score, params in zip(grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"params\"]):\n",
    "    print(f\"mean test score: {test_score}, mean train score: {train_score}, for {params}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.41694694623482675, for {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 200}.\n",
      "mean test score: 0.41570447538107097, mean train score: 0.41570447538107097, for {'criterion': 'gini', 'max_depth': 10000000, 'n_estimators': 200}.\n",
      "mean test score: 0.4099963169867573, mean train score: 0.4099963169867573, for {'criterion': 'gini', 'max_depth': 10000000, 'n_estimators': 100}.\n",
      "mean test score: 0.4031650927662446, mean train score: 0.4031650927662446, for {'criterion': 'gini', 'max_depth': 10000000, 'n_estimators': 50}.\n",
      "mean test score: 0.3498652554255627, mean train score: 0.3498652554255627, for {'criterion': 'gini', 'max_depth': 10000000, 'n_estimators': 10}.\n",
      "mean test score: 0.4131428037638877, mean train score: 0.4131428037638877, for {'criterion': 'gini', 'max_depth': 1000000, 'n_estimators': 200}.\n",
      "mean test score: 0.40840738166188084, mean train score: 0.40840738166188084, for {'criterion': 'gini', 'max_depth': 1000000, 'n_estimators': 100}.\n",
      "mean test score: 0.3965083541190762, mean train score: 0.3965083541190762, for {'criterion': 'gini', 'max_depth': 1000000, 'n_estimators': 50}.\n",
      "mean test score: 0.3498700235092734, mean train score: 0.3498700235092734, for {'criterion': 'gini', 'max_depth': 1000000, 'n_estimators': 10}.\n",
      "mean test score: 0.41562229035607956, mean train score: 0.41562229035607956, for {'criterion': 'gini', 'max_depth': 100000, 'n_estimators': 200}.\n",
      "mean test score: 0.4095898255279577, mean train score: 0.4095898255279577, for {'criterion': 'gini', 'max_depth': 100000, 'n_estimators': 100}.\n",
      "mean test score: 0.3981870817705229, mean train score: 0.3981870817705229, for {'criterion': 'gini', 'max_depth': 100000, 'n_estimators': 50}.\n",
      "mean test score: 0.34728068209445573, mean train score: 0.34728068209445573, for {'criterion': 'gini', 'max_depth': 100000, 'n_estimators': 10}.\n",
      "mean test score: 0.41393425435980874, mean train score: 0.41393425435980874, for {'criterion': 'gini', 'max_depth': 10000, 'n_estimators': 200}.\n",
      "mean test score: 0.4098973890738482, mean train score: 0.4098973890738482, for {'criterion': 'gini', 'max_depth': 10000, 'n_estimators': 100}.\n",
      "mean test score: 0.3997231153756515, mean train score: 0.3997231153756515, for {'criterion': 'gini', 'max_depth': 10000, 'n_estimators': 50}.\n",
      "mean test score: 0.35272116539058157, mean train score: 0.35272116539058157, for {'criterion': 'gini', 'max_depth': 10000, 'n_estimators': 10}.\n",
      "mean test score: 0.411270429924153, mean train score: 0.411270429924153, for {'criterion': 'gini', 'max_depth': 1000, 'n_estimators': 200}.\n",
      "mean test score: 0.40748320486094264, mean train score: 0.40748320486094264, for {'criterion': 'gini', 'max_depth': 1000, 'n_estimators': 100}.\n",
      "mean test score: 0.4038846021212166, mean train score: 0.4038846021212166, for {'criterion': 'gini', 'max_depth': 1000, 'n_estimators': 50}.\n",
      "mean test score: 0.34316578272200066, mean train score: 0.34316578272200066, for {'criterion': 'gini', 'max_depth': 1000, 'n_estimators': 10}.\n",
      "mean test score: 0.41533937147415, mean train score: 0.41533937147415, for {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 200}.\n",
      "mean test score: 0.4089471699557386, mean train score: 0.4089471699557386, for {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 100}.\n",
      "mean test score: 0.40040296546500487, mean train score: 0.40040296546500487, for {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 50}.\n",
      "mean test score: 0.34759533792278163, mean train score: 0.34759533792278163, for {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 10}.\n",
      "mean test score: 0.416300162300161, mean train score: 0.416300162300161, for {'criterion': 'entropy', 'max_depth': 10000000, 'n_estimators': 200}.\n",
      "mean test score: 0.41034346940434735, mean train score: 0.41034346940434735, for {'criterion': 'entropy', 'max_depth': 10000000, 'n_estimators': 100}.\n",
      "mean test score: 0.4030451729819286, mean train score: 0.4030451729819286, for {'criterion': 'entropy', 'max_depth': 10000000, 'n_estimators': 50}.\n",
      "mean test score: 0.3474275424718408, mean train score: 0.3474275424718408, for {'criterion': 'entropy', 'max_depth': 10000000, 'n_estimators': 10}.\n",
      "mean test score: 0.41591061955493824, mean train score: 0.41591061955493824, for {'criterion': 'entropy', 'max_depth': 1000000, 'n_estimators': 200}.\n",
      "mean test score: 0.4105920178886458, mean train score: 0.4105920178886458, for {'criterion': 'entropy', 'max_depth': 1000000, 'n_estimators': 100}.\n",
      "mean test score: 0.4055974259224809, mean train score: 0.4055974259224809, for {'criterion': 'entropy', 'max_depth': 1000000, 'n_estimators': 50}.\n",
      "mean test score: 0.35397729106684983, mean train score: 0.35397729106684983, for {'criterion': 'entropy', 'max_depth': 1000000, 'n_estimators': 10}.\n",
      "mean test score: 0.41337577084360566, mean train score: 0.41337577084360566, for {'criterion': 'entropy', 'max_depth': 100000, 'n_estimators': 200}.\n",
      "mean test score: 0.4139457548290838, mean train score: 0.4139457548290838, for {'criterion': 'entropy', 'max_depth': 100000, 'n_estimators': 100}.\n",
      "mean test score: 0.4056265454513858, mean train score: 0.4056265454513858, for {'criterion': 'entropy', 'max_depth': 100000, 'n_estimators': 50}.\n",
      "mean test score: 0.34851385920935724, mean train score: 0.34851385920935724, for {'criterion': 'entropy', 'max_depth': 100000, 'n_estimators': 10}.\n",
      "mean test score: 0.41498459119218223, mean train score: 0.41498459119218223, for {'criterion': 'entropy', 'max_depth': 10000, 'n_estimators': 200}.\n",
      "mean test score: 0.4105484412599047, mean train score: 0.4105484412599047, for {'criterion': 'entropy', 'max_depth': 10000, 'n_estimators': 100}.\n",
      "mean test score: 0.40296328515286195, mean train score: 0.40296328515286195, for {'criterion': 'entropy', 'max_depth': 10000, 'n_estimators': 50}.\n",
      "mean test score: 0.3484991296500216, mean train score: 0.3484991296500216, for {'criterion': 'entropy', 'max_depth': 10000, 'n_estimators': 10}.\n",
      "mean test score: 0.41477133453377, mean train score: 0.41477133453377, for {'criterion': 'entropy', 'max_depth': 1000, 'n_estimators': 200}.\n",
      "mean test score: 0.4115916176184262, mean train score: 0.4115916176184262, for {'criterion': 'entropy', 'max_depth': 1000, 'n_estimators': 100}.\n",
      "mean test score: 0.40271053185363614, mean train score: 0.40271053185363614, for {'criterion': 'entropy', 'max_depth': 1000, 'n_estimators': 50}.\n",
      "mean test score: 0.3461592320740339, mean train score: 0.3461592320740339, for {'criterion': 'entropy', 'max_depth': 1000, 'n_estimators': 10}.\n",
      "mean test score: 0.41694694623482675, mean train score: 0.41694694623482675, for {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 200}.\n",
      "mean test score: 0.4106520704113311, mean train score: 0.4106520704113311, for {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 100}.\n",
      "mean test score: 0.401904829067124, mean train score: 0.401904829067124, for {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 50}.\n",
      "mean test score: 0.3522198650569875, mean train score: 0.3522198650569875, for {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 10}.\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(class_weight=\"balanced\")\n",
    "param_grid = [\n",
    "    {\"n_estimators\": [200, 100, 50, 10],\n",
    "     \"criterion\": [\"gini\", \"entropy\"],\n",
    "     \"max_depth\": [10000000, 1000000, 100000, 10000, 1000, 100]}\n",
    "    ]\n",
    "grid_search = GridSearchCV(random_forest,\n",
    "                           param_grid,\n",
    "                           scoring=\"average_precision\",\n",
    "                           return_train_score=True,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)\n",
    "grid_fit = grid_search.fit(X_train, y_train)\n",
    "grid_results = grid_search.cv_results_\n",
    "grid_best_params = grid_search.best_params_\n",
    "\n",
    "grid_fit = grid_search.fit(X_train, y_train)\n",
    "grid_results = grid_search.cv_results_\n",
    "grid_best_params = grid_search.best_params_\n",
    "grid_best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"best mean test score: {grid_best_score}, for {grid_best_params}.\")\n",
    "\n",
    "for test_score, train_score, params in zip(grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"mean_test_score\"],\n",
    "                                           grid_results[\"params\"]):\n",
    "    print(f\"mean test score: {test_score}, mean train score: {train_score}, for {params}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "f64e53ca-1b5a-45ec-96fc-21aa4b4e83c8",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
