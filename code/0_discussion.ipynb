{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussions on Data Analytics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(filename):\n",
    "    bank_mkt = pd.read_csv(filename,\n",
    "                           na_values=[\"unknown\", \"nonexistent\"],\n",
    "                           true_values=[\"yes\", \"success\"],\n",
    "                           false_values=[\"no\", \"failure\"])\n",
    "    # Treat pdays = 999 as missing values\n",
    "    bank_mkt[\"pdays\"] = bank_mkt[\"pdays\"].replace(999, pd.NA)\n",
    "    # Convert types, \"Int64\" is nullable integer data type in pandas\n",
    "    bank_mkt = bank_mkt.astype(dtype={\"age\": \"Int64\",\n",
    "                                      \"job\": \"category\",\n",
    "                                      \"marital\": \"category\",\n",
    "                                      \"education\": \"category\",\n",
    "                                      \"default\": \"boolean\",\n",
    "                                      \"housing\": \"boolean\",\n",
    "                                      \"loan\": \"boolean\",\n",
    "                                      \"contact\": \"category\",\n",
    "                                      \"month\": \"category\",\n",
    "                                      \"day_of_week\": \"category\",\n",
    "                                      \"duration\": \"Int64\",\n",
    "                                      \"campaign\": \"Int64\",\n",
    "                                      \"pdays\": \"Int64\",\n",
    "                                      \"previous\": \"Int64\",\n",
    "                                      \"poutcome\": \"boolean\",\n",
    "                                      \"y\": \"boolean\"})\n",
    "    # Drop duplicates\n",
    "    bank_mkt = bank_mkt.drop_duplicates().reset_index(drop=True)\n",
    "    # reorder categorical data\n",
    "    bank_mkt[\"education\"] = bank_mkt[\"education\"].cat.reorder_categories([\"illiterate\", \"basic.4y\", \"basic.6y\", \"basic.9y\", \"high.school\", \"professional.course\", \"university.degree\"], ordered=True)\n",
    "    bank_mkt[\"month\"] = bank_mkt[\"month\"].cat.reorder_categories([\"mar\", \"apr\", \"jun\", \"jul\", \"may\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"], ordered=True)\n",
    "    bank_mkt[\"day_of_week\"] = bank_mkt[\"day_of_week\"].cat.reorder_categories([\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"], ordered=True)\n",
    "    return bank_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_mkt = import_dataset(\"../data/BankMarketing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_split.split(bank_mkt.drop(\"y\", axis=1), bank_mkt[\"y\"]):\n",
    "    bank_train_set = bank_mkt.loc[train_index].reset_index(drop=True)\n",
    "    bank_test_set = bank_mkt.loc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Features May or May Not Change Results\n",
    "- Dropping some features may improve the results.\n",
    "- Test and Validation metrics give different opionions.\n",
    "- Ensemble models with different dropping strategies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with missing values that should be imputed with most freq value\n",
    "freq_features = [\"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Features with missing values that should be imputed by IterativeImputer\n",
    "ite_features = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Features that should be mean encoded\n",
    "# target_features = [\"month\", \"day_of_week\"]\n",
    "# target_features = [1,2,3,8,9,10]\n",
    "\n",
    "# drop_features = [\"age\", \"job\", \"marital\", \"education\", \"housing\", \"loan\", \"default\", \"duration\", \"y\"]\n",
    "drop_features = [\"y\"]\n",
    "\n",
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    #X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[1, 2, 3, 4, 5], include_lowest=True).astype(\"Int64\")\n",
    "    # Cut age into age groups\n",
    "    # X[\"age\"] = pd.cut(X[\"age\"], [0, 18, 24, 30, 35, 40, 45, 50, 55, 60, 100], labels=[18, 24, 30, 35, 40, 45, 50, 55, 60, 100], include_lowest=True).astype(\"Int64\")\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"may\": 5,\n",
    "                 \"jun\": 6,\n",
    "                 \"jul\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    # Drop features\n",
    "    X = X.drop(drop_features, axis=1)\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    X = X.apply(lambda x: x.cat.codes if pd.api.types.is_categorical_dtype(x) else (x.astype(\"Int64\") if pd.api.types.is_bool_dtype(x) else x))\n",
    "    # X[target_features] = X[target_features].astype(\"str\")\n",
    "    # Fill missing values as -1\n",
    "     # X = X.fillna(-1).to_numpy()\n",
    "    X = X.fillna(-1)\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "# freq_imputer will impute missing values in columns specified by freq_features\n",
    "freq_imputer = ColumnTransformer([\n",
    "    (\"freq_imputer\",\n",
    "     SimpleImputer(missing_values=-1, strategy=\"most_frequent\"),\n",
    "     freq_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", tree_encoder),\n",
    "    (\"freq_imputer\", freq_imputer)\n",
    "])\n",
    "\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_train = tree_preprocessor.fit_transform(bank_train_set)\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_test = tree_preprocessor.transform(bank_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=62)\n",
    "\n",
    "for train_index, validate_index in train_validate_split.split(X_train, y_train):\n",
    "    X_ttrain = X_train[train_index]\n",
    "    y_ttrain = y_train[train_index]\n",
    "    X_validate = X_train[validate_index]\n",
    "    y_validate = y_train[validate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.875422</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.864122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.921833</td>\n",
       "      <td>0.921336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.895402</td>\n",
       "      <td>0.892729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.968406</td>\n",
       "      <td>0.947962</td>\n",
       "      <td>0.950264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.921833</td>\n",
       "      <td>0.921336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.495410</td>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.462662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.654313</td>\n",
       "      <td>0.624088</td>\n",
       "      <td>0.615994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.780295</td>\n",
       "      <td>0.651880</td>\n",
       "      <td>0.671839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validate      Test\n",
       "TNR   0.875422  0.868970  0.864122\n",
       "TPR   0.963287  0.921833  0.921336\n",
       "bACC  0.919355  0.895402  0.892729\n",
       "ROC   0.968406  0.947962  0.950264\n",
       "REC   0.963287  0.921833  0.921336\n",
       "PRE   0.495410  0.471724  0.462662\n",
       "F1    0.654313  0.624088  0.615994\n",
       "AP    0.780295  0.651880  0.671839"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(eval_metric=\"AUC\", class_weights=[1, 8])\n",
    "cat_fit = cat_clf.fit(X_ttrain, y_ttrain, eval_set=(X_validate, y_validate), verbose=False)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validate\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = cat_clf.predict(X)\n",
    "    y_score = cat_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with missing values that should be imputed with most freq value\n",
    "freq_features = [\"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Features with missing values that should be imputed by IterativeImputer\n",
    "ite_features = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Features that should be mean encoded\n",
    "# target_features = [\"month\", \"day_of_week\"]\n",
    "# target_features = [1,2,3,8,9,10]\n",
    "\n",
    "# drop_features = [\"age\", \"job\", \"marital\", \"education\", \"housing\", \"loan\", \"default\", \"duration\", \"y\"]\n",
    "drop_features = [\"duration\", \"y\"]\n",
    "\n",
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    #X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[1, 2, 3, 4, 5], include_lowest=True).astype(\"Int64\")\n",
    "    # Cut age into age groups\n",
    "    # X[\"age\"] = pd.cut(X[\"age\"], [0, 18, 24, 30, 35, 40, 45, 50, 55, 60, 100], labels=[18, 24, 30, 35, 40, 45, 50, 55, 60, 100], include_lowest=True).astype(\"Int64\")\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"may\": 5,\n",
    "                 \"jun\": 6,\n",
    "                 \"jul\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    # Drop features\n",
    "    X = X.drop(drop_features, axis=1)\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    X = X.apply(lambda x: x.cat.codes if pd.api.types.is_categorical_dtype(x) else (x.astype(\"Int64\") if pd.api.types.is_bool_dtype(x) else x))\n",
    "    # X[target_features] = X[target_features].astype(\"str\")\n",
    "    # Fill missing values as -1\n",
    "     # X = X.fillna(-1).to_numpy()\n",
    "    X = X.fillna(-1)\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "# freq_imputer will impute missing values in columns specified by freq_features\n",
    "freq_imputer = ColumnTransformer([\n",
    "    (\"freq_imputer\",\n",
    "     SimpleImputer(missing_values=-1, strategy=\"most_frequent\"),\n",
    "     freq_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", tree_encoder),\n",
    "    (\"freq_imputer\", freq_imputer)\n",
    "])\n",
    "\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_train = tree_preprocessor.fit_transform(bank_train_set)\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_test = tree_preprocessor.transform(bank_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_validate_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=62)\n",
    "\n",
    "for train_index, validate_index in train_validate_split.split(X_train, y_train):\n",
    "    X_ttrain = X_train[train_index]\n",
    "    y_ttrain = y_train[train_index]\n",
    "    X_validate = X_train[validate_index]\n",
    "    y_validate = y_train[validate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.860839</td>\n",
       "      <td>0.859562</td>\n",
       "      <td>0.862343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.656787</td>\n",
       "      <td>0.614555</td>\n",
       "      <td>0.660560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.758813</td>\n",
       "      <td>0.737059</td>\n",
       "      <td>0.761451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.844240</td>\n",
       "      <td>0.797126</td>\n",
       "      <td>0.809376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.656787</td>\n",
       "      <td>0.614555</td>\n",
       "      <td>0.660560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.374712</td>\n",
       "      <td>0.357087</td>\n",
       "      <td>0.378629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.477181</td>\n",
       "      <td>0.451709</td>\n",
       "      <td>0.481351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.527415</td>\n",
       "      <td>0.470583</td>\n",
       "      <td>0.476541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validate      Test\n",
       "TNR   0.860839  0.859562  0.862343\n",
       "TPR   0.656787  0.614555  0.660560\n",
       "bACC  0.758813  0.737059  0.761451\n",
       "ROC   0.844240  0.797126  0.809376\n",
       "REC   0.656787  0.614555  0.660560\n",
       "PRE   0.374712  0.357087  0.378629\n",
       "F1    0.477181  0.451709  0.481351\n",
       "AP    0.527415  0.470583  0.476541"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(eval_metric=\"AUC\", class_weights=[1, 8])\n",
    "cat_fit = cat_clf.fit(X_ttrain, y_ttrain, eval_set=(X_validate, y_validate), verbose=False)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validate\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = cat_clf.predict(X)\n",
    "    y_score = cat_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Almost Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = [\"age\", \"job\", \"marital\", \"education\", \"housing\", \"loan\", \"default\", \"y\"]\n",
    "\n",
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    #X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[1, 2, 3, 4, 5], include_lowest=True).astype(\"Int64\")\n",
    "    # Cut age into age groups\n",
    "    # X[\"age\"] = pd.cut(X[\"age\"], [0, 18, 24, 30, 35, 40, 45, 50, 55, 60, 100], labels=[18, 24, 30, 35, 40, 45, 50, 55, 60, 100], include_lowest=True).astype(\"Int64\")\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"may\": 5,\n",
    "                 \"jun\": 6,\n",
    "                 \"jul\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    # Drop features\n",
    "    X = X.drop(drop_features, axis=1)\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    X = X.apply(lambda x: x.cat.codes if pd.api.types.is_categorical_dtype(x) else (x.astype(\"Int64\") if pd.api.types.is_bool_dtype(x) else x))\n",
    "    # X[target_features] = X[target_features].astype(\"str\")\n",
    "    # Fill missing values as -1\n",
    "    X = X.fillna(-1).to_numpy()\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", tree_encoder)\n",
    "])\n",
    "\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_train = tree_preprocessor.fit_transform(bank_train_set)\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_test = tree_preprocessor.transform(bank_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_validate_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=62)\n",
    "\n",
    "for train_index, validate_index in train_validate_split.split(X_train, y_train):\n",
    "    X_ttrain = X_train[train_index]\n",
    "    y_ttrain = y_train[train_index]\n",
    "    X_validate = X_train[validate_index]\n",
    "    y_validate = y_train[validate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.864987</td>\n",
       "      <td>0.858536</td>\n",
       "      <td>0.857553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.957561</td>\n",
       "      <td>0.913747</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.911274</td>\n",
       "      <td>0.886141</td>\n",
       "      <td>0.894294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.948381</td>\n",
       "      <td>0.948905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.957561</td>\n",
       "      <td>0.913747</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.473833</td>\n",
       "      <td>0.450498</td>\n",
       "      <td>0.453543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.633961</td>\n",
       "      <td>0.603471</td>\n",
       "      <td>0.609954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.746284</td>\n",
       "      <td>0.661880</td>\n",
       "      <td>0.665315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validate      Test\n",
       "TNR   0.864987  0.858536  0.857553\n",
       "TPR   0.957561  0.913747  0.931034\n",
       "bACC  0.911274  0.886141  0.894294\n",
       "ROC   0.962667  0.948381  0.948905\n",
       "REC   0.957561  0.913747  0.931034\n",
       "PRE   0.473833  0.450498  0.453543\n",
       "F1    0.633961  0.603471  0.609954\n",
       "AP    0.746284  0.661880  0.665315"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(eval_metric=\"AUC\", class_weights=[1, 8])\n",
    "cat_fit = cat_clf.fit(X_ttrain, y_ttrain, eval_set=(X_validate, y_validate), verbose=False)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validate\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = cat_clf.predict(X)\n",
    "    y_score = cat_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = [\"age\", \"job\", \"marital\", \"education\", \"housing\", \"loan\", \"default\", \"duration\", \"y\"]\n",
    "\n",
    "def tree_encode(X):\n",
    "    \"\"\"\n",
    "    Encode categorical data into numerical values.\n",
    "    pdays column will be feature engineered and discretized.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    # pdays column will be feature engineered and discretized.\n",
    "    X.loc[X[\"pdays\"].isna() & X[\"poutcome\"].notna(), \"pdays\"] = 999\n",
    "    #X[\"pdays\"] = pd.cut(X[\"pdays\"], [0, 5, 10, 15, 30, 1000], labels=[1, 2, 3, 4, 5], include_lowest=True).astype(\"Int64\")\n",
    "    # Cut age into age groups\n",
    "    # X[\"age\"] = pd.cut(X[\"age\"], [0, 18, 24, 30, 35, 40, 45, 50, 55, 60, 100], labels=[18, 24, 30, 35, 40, 45, 50, 55, 60, 100], include_lowest=True).astype(\"Int64\")\n",
    "    # Encode nominal and ordinal features\n",
    "    # `month` will be encoded to the corresponding number, e.g. \"mar\" -> 3.\n",
    "    month_map = {\"mar\": 3,\n",
    "                 \"apr\": 4,\n",
    "                 \"may\": 5,\n",
    "                 \"jun\": 6,\n",
    "                 \"jul\": 7,\n",
    "                 \"aug\": 8,\n",
    "                 \"sep\": 9,\n",
    "                 \"oct\": 10,\n",
    "                 \"nov\": 11,\n",
    "                 \"dec\": 12}\n",
    "    # Drop features\n",
    "    X = X.drop(drop_features, axis=1)\n",
    "    # Other categorical features will be coded as its order in pandas categorical index\n",
    "    X = X.apply(lambda x: x.cat.codes if pd.api.types.is_categorical_dtype(x) else (x.astype(\"Int64\") if pd.api.types.is_bool_dtype(x) else x))\n",
    "    # X[target_features] = X[target_features].astype(\"str\")\n",
    "    # Fill missing values as -1\n",
    "    X = X.fillna(-1).to_numpy()\n",
    "    return X\n",
    "\n",
    "tree_encoder = FunctionTransformer(tree_encode)\n",
    "\n",
    "tree_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", tree_encoder)\n",
    "])\n",
    "\n",
    "y_train = bank_train_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_train = tree_preprocessor.fit_transform(bank_train_set)\n",
    "y_test = bank_test_set[\"y\"].astype(\"int\").to_numpy()\n",
    "X_test = tree_preprocessor.transform(bank_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_validate_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=62)\n",
    "\n",
    "for train_index, validate_index in train_validate_split.split(X_train, y_train):\n",
    "    X_ttrain = X_train[train_index]\n",
    "    y_ttrain = y_train[train_index]\n",
    "    X_validate = X_train[validate_index]\n",
    "    y_validate = y_train[validate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.867254</td>\n",
       "      <td>0.866062</td>\n",
       "      <td>0.865764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.639272</td>\n",
       "      <td>0.611860</td>\n",
       "      <td>0.615302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bACC</th>\n",
       "      <td>0.753263</td>\n",
       "      <td>0.738961</td>\n",
       "      <td>0.740533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>0.816888</td>\n",
       "      <td>0.793971</td>\n",
       "      <td>0.804984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REC</th>\n",
       "      <td>0.639272</td>\n",
       "      <td>0.611860</td>\n",
       "      <td>0.615302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.379448</td>\n",
       "      <td>0.367017</td>\n",
       "      <td>0.367912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.476226</td>\n",
       "      <td>0.458818</td>\n",
       "      <td>0.460484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.499583</td>\n",
       "      <td>0.460966</td>\n",
       "      <td>0.458497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validate      Test\n",
       "TNR   0.867254  0.866062  0.865764\n",
       "TPR   0.639272  0.611860  0.615302\n",
       "bACC  0.753263  0.738961  0.740533\n",
       "ROC   0.816888  0.793971  0.804984\n",
       "REC   0.639272  0.611860  0.615302\n",
       "PRE   0.379448  0.367017  0.367912\n",
       "F1    0.476226  0.458818  0.460484\n",
       "AP    0.499583  0.460966  0.458497"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(eval_metric=\"AUC\", class_weights=[1, 8])\n",
    "cat_fit = cat_clf.fit(X_ttrain, y_ttrain, eval_set=(X_validate, y_validate), verbose=False)\n",
    "\n",
    "X_sets = [X_ttrain, X_validate, X_test]\n",
    "y_sets = [y_ttrain, y_validate, y_test]\n",
    "\n",
    "matric_names = [\"TNR\", \"TPR\", \"bACC\", \"ROC\", \"REC\", \"PRE\", \"F1\", \"AP\"]\n",
    "set_names = [\"Train\", \"Validate\", \"Test\"]\n",
    "matric_df = pd.DataFrame(index=matric_names, columns=set_names)\n",
    "\n",
    "for name, X, y in zip(set_names, X_sets, y_sets):\n",
    "    y_pred = cat_clf.predict(X)\n",
    "    y_score = cat_clf.predict_proba(X)[:,1]\n",
    "    matrics = [recall_score(y, y_pred, pos_label=0),\n",
    "               recall_score(y, y_pred),\n",
    "               balanced_accuracy_score(y, y_pred),\n",
    "               roc_auc_score(y, y_score),\n",
    "               recall_score(y, y_pred),\n",
    "               precision_score(y, y_pred),\n",
    "               f1_score(y, y_pred),\n",
    "               average_precision_score(y, y_score)]\n",
    "    matric_df[name] = matrics\n",
    "\n",
    "matric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization on Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preprocessor = Pipeline([\n",
    "    (\"tree_encoder\", svm_encoder),\n",
    "    (\"ite_transformer\", ite_transformer),\n",
    "    (\"one_hot_encoder\", one_hot_encoder), # Standardize Dummy Variables?\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preprocessor = Pipeline([\n",
    "    (\"svm_encoder\", svm_encoder),\n",
    "    (\"freq_imputer\", freq_imputer), # Iterative Imputer?\n",
    "    (\"one_hot_encoder\", one_hot_encoder), # Target Encoding? Frequency Encoding?\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rbf\", RBFSampler(random_state=42)), # Kernel Approxmation or Use less data?\n",
    "    (\"svm\", SGDClassifier(class_weight=\"balanced\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding Methods\n",
    "\n",
    "- Mean encoding\n",
    "- Frequency encoding\n",
    "- Cyclic encoding\n",
    "- Entity Embedding, new ways to work with categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Ideas\n",
    "\n",
    "- What's the starting point for ensembles?\n",
    "\n",
    "- KNN + Decision Tress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate More Infomation\n",
    "\n",
    "- Gold price? \n",
    "- Currency rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
